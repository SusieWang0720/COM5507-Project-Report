{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba55988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0afc3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1页爬取完毕\n",
      "第2页爬取完毕\n",
      "第3页爬取完毕\n",
      "第4页爬取完毕\n",
      "第5页爬取完毕\n",
      "第6页爬取完毕\n",
      "第7页爬取完毕\n",
      "第8页爬取完毕\n",
      "第9页爬取完毕\n",
      "第10页爬取完毕\n",
      "第11页爬取完毕\n",
      "第12页爬取完毕\n",
      "第13页爬取完毕\n",
      "第14页爬取完毕\n",
      "第15页爬取完毕\n",
      "第16页爬取完毕\n",
      "第17页爬取完毕\n",
      "第18页爬取完毕\n",
      "第19页爬取完毕\n",
      "第20页爬取完毕\n"
     ]
    }
   ],
   "source": [
    "cookies = {\n",
    "    'smidV2': '20231204033332b52f94902bd675693c650fc4ffae2c2800b9f3279ddffe820',\n",
    "    'sensorsdata2015jssdkcross': '%7B%22distinct_id%22%3A%2218c312c28b210f7-087ff702993fb38-16525634-1296000-18c312c28b3144f%22%2C%22first_id%22%3A%22%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%2C%22%24latest_referrer%22%3A%22%22%7D%2C%22%24device_id%22%3A%2218c312c28b210f7-087ff702993fb38-16525634-1296000-18c312c28b3144f%22%2C%22identities%22%3A%22eyIkaWRlbnRpdHlfYW5vbnltb3VzX2lkIjoiMThjMzEyYzI4YjIxMGY3LTA4N2ZmNzAyOTkzZmIzOC0xNjUyNTYzNC0xMjk2MDAwLTE4YzMxMmMyOGIzMTQ0ZiIsIiRpZGVudGl0eV9jb29raWVfaWQiOiIxOGMzMTJjZmVjMTNkOC0wN2FjM2FiNzA3MTdmMy0xNjUyNTYzNC0xMjk2MDAwLTE4YzMxMmNmZWMyMWFmMyJ9%22%2C%22history_login_id%22%3A%7B%22name%22%3A%22%22%2C%22value%22%3A%22%22%7D%7D',\n",
    "    'acw_tc': '2f624a2017028761944373100e6ccf83b39388bede53ee13190a95e8f50b07',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'authority': 'my.hupu.com',\n",
    "    'accept': 'application/json, text/plain, */*',\n",
    "    'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8',\n",
    "    # Requests sorts cookies= alphabetically\n",
    "    # 'cookie': 'smidV2=20231204033332b52f94902bd675693c650fc4ffae2c2800b9f3279ddffe820; sensorsdata2015jssdkcross=%7B%22distinct_id%22%3A%2218c312c28b210f7-087ff702993fb38-16525634-1296000-18c312c28b3144f%22%2C%22first_id%22%3A%22%22%2C%22props%22%3A%7B%22%24latest_traffic_source_type%22%3A%22%E7%9B%B4%E6%8E%A5%E6%B5%81%E9%87%8F%22%2C%22%24latest_search_keyword%22%3A%22%E6%9C%AA%E5%8F%96%E5%88%B0%E5%80%BC_%E7%9B%B4%E6%8E%A5%E6%89%93%E5%BC%80%22%2C%22%24latest_referrer%22%3A%22%22%7D%2C%22%24device_id%22%3A%2218c312c28b210f7-087ff702993fb38-16525634-1296000-18c312c28b3144f%22%2C%22identities%22%3A%22eyIkaWRlbnRpdHlfYW5vbnltb3VzX2lkIjoiMThjMzEyYzI4YjIxMGY3LTA4N2ZmNzAyOTkzZmIzOC0xNjUyNTYzNC0xMjk2MDAwLTE4YzMxMmMyOGIzMTQ0ZiIsIiRpZGVudGl0eV9jb29raWVfaWQiOiIxOGMzMTJjZmVjMTNkOC0wN2FjM2FiNzA3MTdmMy0xNjUyNTYzNC0xMjk2MDAwLTE4YzMxMmNmZWMyMWFmMyJ9%22%2C%22history_login_id%22%3A%7B%22name%22%3A%22%22%2C%22value%22%3A%22%22%7D%7D; acw_tc=2f624a2017028761944373100e6ccf83b39388bede53ee13190a95e8f50b07',\n",
    "    'origin': 'https://bbs.hupu.com',\n",
    "    'referer': 'https://bbs.hupu.com/',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"119\", \"Chromium\";v=\"119\", \"Not?A_Brand\";v=\"24\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-site': 'same-site',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "aweme_id = '7300076561292676402'\n",
    "lists = []\n",
    "\n",
    "reply_num = 100\n",
    "\n",
    "\n",
    "try:\n",
    "    for page in range(20):\n",
    "        response = requests.get(\n",
    "            f'https://bbs.hupu.com/search?q=%E6%9D%8E%E4%BD%B3%E7%90%A6%E8%8A%B1%E8%A5%BF%E5%AD%90&topicId=&sortby=general&page={page}',\n",
    "            headers=headers, cookies=cookies\n",
    "        )\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        search_results = soup.find_all(\"div\", class_=\"content-wrap\")\n",
    "\n",
    "        for result in search_results:\n",
    "            lst = []\n",
    "            text = result.a.text.strip('\\u200b')\n",
    "            link = result.a['href']\n",
    "            create_time = result.find('span').text\n",
    "            lst.append(create_time)\n",
    "            lst.append(text)\n",
    "            lst.append(link)\n",
    "\n",
    "            # Now, let's fetch the detailed content from each post's page\n",
    "            post_response = requests.get(link, headers=headers, cookies=cookies)\n",
    "            post_soup = BeautifulSoup(post_response.text, 'html.parser')\n",
    "\n",
    "            # Adjust the selector according to the actual HTML structure of the detailed content\n",
    "            detailed_content = post_soup.find(\"div\", class_=\"thread-content-detail\")\n",
    "            reply_info = post_soup.find_all(\"div\", class_=\"reply-list-content\")\n",
    "            reply_list = []\n",
    "            for info in reply_info:\n",
    "                reply_user = info.find(\"div\", class_='user-base-info')\n",
    "                reply_user = reply_user.find(\"a\", class_='post-reply-list-user-info-top-name')\n",
    "                if not reply_user:\n",
    "                    reply_user = \"\"\n",
    "                reply_content = info.find(\"div\", class_=\"thread-content-detail\")\n",
    "                if not reply_content:\n",
    "                    reply_content = \"\"\n",
    "                if reply_user and reply_content:\n",
    "                    reply_list.append([reply_content.get_text(strip=True)])\n",
    "\n",
    "            # Assuming detailed content is in a div with class 'detailed-content'\n",
    "            if detailed_content:\n",
    "                detailed_content_text = detailed_content.get_text(strip=True)\n",
    "                lst.append(detailed_content_text)\n",
    "            else:\n",
    "                lst.append(\"\")\n",
    "\n",
    "            for i in range(reply_num):\n",
    "                if i >= len(reply_list) - 1:\n",
    "                    # lst.append(\"\")\n",
    "                    lst.append(\"\")\n",
    "                else:\n",
    "                    lst.extend(reply_list[i])\n",
    "\n",
    "            lists.append(lst)\n",
    "\n",
    "            # Close the detailed content page response\n",
    "            post_response.close()\n",
    "\n",
    "        response.close()\n",
    "        print(f'第{page + 1}页爬取完毕')\n",
    "except Exception as e:\n",
    "    raise e\n",
    "    # print('爬取完毕')\n",
    "columns = ['创建时间', '内容', '链接', '详细内容']\n",
    "for i in range(reply_num):\n",
    "    columns += [f'评论{i + 1}内容']\n",
    "\n",
    "df = pd.DataFrame(lists, columns=columns)\n",
    "\n",
    "# 保存到本地excel\n",
    "df.to_excel(f\"{aweme_id}.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90293106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
